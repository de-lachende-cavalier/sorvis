- [x] finish reviewing the material on distill
- [x] separate the useful code from the visualization et alia and put it into a separate notebook
  - [x] create a git repo to track everything (it will be the project repo)
- [x] check that training progresses as it should (something weird seems to be happening?)
  - [x] check the tensor shapes and track everything (!)
- [x] read and understand the mnist CA distill article and rebuild the model (in simplified form, as before)
- [x] download quick! draw data (only some classes are enough, probably)
- [x] switch back to MNIST for further experiments (we have pretty good pretrained models at our disposal for that!)
- [ ] run some experiments (check notes!)
- [ ] make the main notebook more verbose
- [Â ] write a better README!

## Presentation
- [ ] include some results by Risi et al.
- [ ] looking to the future
    - LLM -> RL coordinator; RL coordinator -> NCA; NCA -> growing desired result
    - "grow me an eye", e.g.
    - big hero 6, e.g.
