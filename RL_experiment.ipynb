{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility study of using Reinforcement Learning to grow NCAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a simplified (sanity) test, to make sure that this approach could be interesting/useful/worth pursuing.\n",
    "\n",
    "It considers a simplified problem, that of coloring a 3x3 square a specified color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "from NCAEnv import NCAEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = NCAEnv()\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(18), Box(0, 1, (9,), int32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done,_, _ = env.step(action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# overkill, but it shall serve us well later\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 874       |\n",
      "|    ep_rew_mean     | -3.96e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 7009      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 542         |\n",
      "|    ep_rew_mean          | -2.25e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4517        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014375439 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | -0.00048    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 4.95e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 164         |\n",
      "|    ep_rew_mean          | -619        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3889        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017897036 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.0168     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | -374        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3716        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017816164 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | -0.00739    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 610         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.8        |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3648        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014540762 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | -0.0036     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 453         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 844         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.9        |\n",
      "|    ep_rew_mean          | -58.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3617        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018689606 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | -0.00132    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 602         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.6        |\n",
      "|    ep_rew_mean          | -35.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3600        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021544747 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | -0.00104    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 542         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.6        |\n",
      "|    ep_rew_mean          | -28.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3586        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008797175 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | -0.000174   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.5         |\n",
      "|    ep_rew_mean          | -28          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3573         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060594706 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | -0.000136    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 252          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.7        |\n",
      "|    ep_rew_mean          | -23         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3561        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010079166 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | -0.000135   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77          |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1055bd490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
