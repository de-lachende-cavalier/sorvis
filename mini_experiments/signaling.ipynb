{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signaling experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some code for experimenting with the signaling between two NCAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import PIL.Image, PIL.ImageDraw\n",
    "import base64\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "from IPython.display import Image, clear_output\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
    "import moviepy.editor as mvp\n",
    "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2pil(a):\n",
    "  if a.dtype in [np.float32, np.float64]:\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None):\n",
    "  a = np.asarray(a)\n",
    "  if isinstance(f, str):\n",
    "    fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "      fmt = 'jpeg'\n",
    "    f = open(f, 'wb')\n",
    "  np2pil(a).save(f, fmt, quality=95)\n",
    "\n",
    "def imencode(a, fmt='jpeg'):\n",
    "  a = np.asarray(a)\n",
    "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
    "    fmt = 'png'\n",
    "  f = io.BytesIO()\n",
    "  imwrite(f, a, fmt)\n",
    "  return f.getvalue()\n",
    "\n",
    "def im2url(a, fmt='jpeg'):\n",
    "  encoded = imencode(a, fmt)\n",
    "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
    "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "  display(Image(data=imencode(a, fmt)))\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "  a = np.asarray(a)\n",
    "  if w is None:\n",
    "    w = int(np.ceil(np.sqrt(len(a))))\n",
    "  th, tw = a.shape[1:3]\n",
    "  pad = (w-len(a))%w\n",
    "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
    "  h = len(a)//w\n",
    "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
    "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
    "  return a\n",
    "\n",
    "def zoom(img, scale=4):\n",
    "  img = np.repeat(img, scale, 0)\n",
    "  img = np.repeat(img, scale, 1)\n",
    "  return img\n",
    "\n",
    "class VideoWriter:\n",
    "  def __init__(self, filename, fps=30.0, **kw):\n",
    "    self.writer = None\n",
    "    self.params = dict(filename=filename, fps=fps, **kw)\n",
    "\n",
    "  def add(self, img):\n",
    "    img = np.asarray(img)\n",
    "    if self.writer is None:\n",
    "      h, w = img.shape[:2]\n",
    "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
    "    if img.dtype in [np.float32, np.float64]:\n",
    "      img = np.uint8(img.clip(0, 1)*255)\n",
    "    if len(img.shape) == 2:\n",
    "      img = np.repeat(img[..., None], 3, -1)\n",
    "    if len(img.shape) == 3 and img.shape[-1] == 4:\n",
    "      img = img[..., :3] * img[..., 3, None]\n",
    "    self.writer.write_frame(img)\n",
    "\n",
    "  def close(self):\n",
    "    if self.writer:\n",
    "      self.writer.close()\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "\n",
    "  def __exit__(self, *kw):\n",
    "    self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = np.array(x_train / 255.0,).astype(np.float32)\n",
    "x_test = np.array(x_test / 255.0,).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the problem into a binary classification one for simplicity\n",
    "mask_train = (y_train == 0) | (y_train == 1) | (y_train == 2)\n",
    "mask_test = (y_test == 0) | (y_test == 1) | (y_test == 2)\n",
    "\n",
    "x_train = x_train[mask_train]\n",
    "y_train = y_train[mask_train]\n",
    "x_test = x_test[mask_test]\n",
    "y_test = y_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lookup = tf.constant([\n",
    "            [128, 0, 0],\n",
    "            [70, 240, 240],\n",
    "            [250, 190, 190],\n",
    "            \n",
    "            [0, 0, 0], # default for digits.\n",
    "            [255, 255, 255] # This is the background.\n",
    "            ])\n",
    "backgroundWhite = True\n",
    "\n",
    "def color_labels(x, y_pic, disable_black=False, dtype=tf.uint8):\n",
    "  # works for shapes of x [b, r, c] and [r, c]\n",
    "  black_and_white = tf.fill(list(x.shape) + [2], 0.01)\n",
    "  is_gray = tf.cast(x > 0.1, tf.float32)\n",
    "  is_not_gray = 1. - is_gray\n",
    "\n",
    "  y_pic = y_pic * tf.expand_dims(is_gray, -1) # forcibly cancels everything outside of it.\n",
    "  \n",
    "  # if disable_black, make is_gray super low.\n",
    "  if disable_black:\n",
    "    is_gray *= -1e5\n",
    "    # this ensures that you don't draw white in the digits.\n",
    "    is_not_gray += is_gray\n",
    "\n",
    "  bnw_order = [is_gray, is_not_gray] if backgroundWhite else [is_not_gray, is_gray]\n",
    "  black_and_white *= tf.stack(bnw_order, -1)\n",
    "\n",
    "  rgb = tf.gather(\n",
    "      color_lookup,\n",
    "      tf.argmax(tf.concat([y_pic, black_and_white], -1), -1))\n",
    "  if dtype == tf.uint8:\n",
    "    return tf.cast(rgb, tf.uint8)\n",
    "  else:\n",
    "    return tf.cast(rgb, dtype) / 255.\n",
    "\n",
    "def to_two_dim_label(x, y):\n",
    "  # x shape is [b, r, c]\n",
    "  # y shape is [b]\n",
    "\n",
    "  # y_res shape is [b, r, c, 2]\n",
    "  y_res = np.zeros(list(x.shape) + [3])\n",
    "  # broadcast y to match x shape:\n",
    "  y_expanded = np.broadcast_to(y, x.T.shape).T\n",
    "  y_res[x >= 0.1, y_expanded[x >= 0.1]] = 1.0\n",
    "  return y_res.astype(np.float32)\n",
    "\n",
    "def find_different_numbers(x_set, y_set, y_set_pic, orientation=\"vertical\"):\n",
    "  result_y = []\n",
    "  result_x = []\n",
    "  for i in range(3):\n",
    "    for x, y, y_pic in zip(x_set, y_set, y_set_pic):\n",
    "      if y == i:\n",
    "        result_y.append(color_labels(x, y_pic))\n",
    "        result_x.append(x)\n",
    "        break\n",
    "  assert len(result_y) == 3\n",
    "\n",
    "  result_y = np.concatenate(result_y, axis=0 if orientation == \"vertical\" else 1)\n",
    "  result_x = np.stack(result_x)\n",
    "\n",
    "  return result_y, result_x\n",
    "\n",
    "y_train_pic = to_two_dim_label(x_train, y_train)\n",
    "y_test_pic = to_two_dim_label(x_test, y_test)\n",
    "\n",
    "numbers_legend, x_legend = find_different_numbers(x_train, y_train, y_train_pic)\n",
    "numbers_legend_horiz, _ = find_different_numbers(x_train, y_train, y_train_pic, \"horizontal\")\n",
    "\n",
    "imshow(zoom(numbers_legend_horiz))\n",
    "\n",
    "print(\"Storing x_legend for use in the demo.\")\n",
    "pl.imshow(x_legend.reshape((-1, 28)))\n",
    "samples_str = json.dumps(x_legend.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_n = 11\n",
    "# TODO get the figures and pretrained code from the mnist_ca notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
